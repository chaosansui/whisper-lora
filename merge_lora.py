import argparse
import os
from transformers import WhisperForConditionalGeneration, WhisperFeatureExtractor, WhisperTokenizerFast, WhisperProcessor
from peft import PeftModel

def validate_path(path, is_dir=False):
    """æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œå¹¶éªŒè¯æ˜¯å¦ä¸ºç›®å½•ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
    if not os.path.exists(path):
        raise FileNotFoundError(f"è·¯å¾„ä¸å­˜åœ¨: {path}")
    if is_dir and not os.path.isdir(path):
        raise NotADirectoryError(f"è·¯å¾„ä¸æ˜¯ç›®å½•: {path}")
    return path

def main():
    # å‚æ•°è®¾ç½®
    parser = argparse.ArgumentParser(description="åˆå¹¶ Whisper åŸºç¡€æ¨¡å‹å’Œ LoRA é€‚é…å™¨")
    parser.add_argument("--base_model", type=str, required=True, help="æœ¬åœ°åŸºç¡€æ¨¡å‹è·¯å¾„")
    parser.add_argument("--lora_model", type=str, required=True, help="LoRAé€‚é…å™¨è·¯å¾„")
    parser.add_argument("--output_dir", type=str, default="merged_model", help="åˆå¹¶åæ¨¡å‹ä¿å­˜è·¯å¾„")
    parser.add_argument("--local_files_only", action="store_true", help="æ˜¯å¦ä»…ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆä¸ä¸‹è½½ï¼‰")
    args = parser.parse_args()

    # æ£€æŸ¥è·¯å¾„
    args.base_model = validate_path(args.base_model, is_dir=True)
    args.lora_model = validate_path(args.lora_model, is_dir=True)
    os.makedirs(args.output_dir, exist_ok=True)

    print(f"ğŸ”„ åŠ è½½åŸºç¡€æ¨¡å‹ä»: {args.base_model}")
    try:
        base_model = WhisperForConditionalGeneration.from_pretrained(
            args.base_model,
            device_map={"": "cpu"},
            local_files_only=args.local_files_only
        )
    except Exception as e:
        print(f"âŒ åŠ è½½åŸºç¡€æ¨¡å‹å¤±è´¥: {e}")
        exit(1)

    print(f"ğŸ”„ åŠ è½½LoRAé€‚é…å™¨ä»: {args.lora_model}")
    try:
        model = PeftModel.from_pretrained(
            base_model,
            args.lora_model,
            device_map={"": "cpu"},
            local_files_only=args.local_files_only
        )
    except Exception as e:
        print(f"âŒ åŠ è½½LoRAé€‚é…å™¨å¤±è´¥: {e}")
        exit(1)

    # åˆå¹¶æ¨¡å‹
    print("â³ å¼€å§‹åˆå¹¶æ¨¡å‹...")
    try:
        merged_model = model.merge_and_unload()
        merged_model.eval()
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå¹¶å¤±è´¥: {e}")
        exit(1)

    # åŠ è½½å¤„ç†å™¨
    print("ğŸ”„ åŠ è½½å¤„ç†å™¨ç»„ä»¶...")
    try:
        feature_extractor = WhisperFeatureExtractor.from_pretrained(args.base_model, local_files_only=args.local_files_only)
        tokenizer = WhisperTokenizerFast.from_pretrained(args.base_model, local_files_only=args.local_files_only)
        processor = WhisperProcessor.from_pretrained(args.base_model, local_files_only=args.local_files_only)
    except Exception as e:
        print(f"âŒ åŠ è½½å¤„ç†å™¨å¤±è´¥: {e}")
        exit(1)

    # ä¿å­˜åˆå¹¶åçš„æ¨¡å‹
    print(f"ğŸ’¾ ä¿å­˜åˆå¹¶æ¨¡å‹åˆ°: {args.output_dir}")
    try:
        merged_model.save_pretrained(args.output_dir, max_shard_size="4GB")
        feature_extractor.save_pretrained(args.output_dir)
        tokenizer.save_pretrained(args.output_dir)
        processor.save_pretrained(args.output_dir)
    except Exception as e:
        print(f"âŒ ä¿å­˜æ¨¡å‹å¤±è´¥: {e}")
        exit(1)

    print("âœ… åˆå¹¶å®Œæˆï¼è¾“å‡ºç›®å½•:", os.path.abspath(args.output_dir))

if __name__ == "__main__":
    main()